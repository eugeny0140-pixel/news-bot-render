import os
import re
import asyncio
import logging
from datetime import datetime
from telegram import Bot
from supabase import create_client
import aiohttp
import feedparser
from http.server import BaseHTTPRequestHandler, HTTPServer
import threading

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHANNEL_IDS = [os.getenv("CHANNEL_ID1"), os.getenv("CHANNEL_ID2")]
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
PORT = int(os.getenv("PORT", 10000))

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
required_vars = ["TELEGRAM_TOKEN", "CHANNEL_ID1", "SUPABASE_URL", "SUPABASE_KEY"]
missing_vars = [var for var in required_vars if not os.getenv(var)]
if missing_vars:
    logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {', '.join(missing_vars)}")
    exit(1)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
BOT = Bot(token=TELEGRAM_TOKEN)
SUPABASE = create_client(SUPABASE_URL, SUPABASE_KEY)

# === –ò–°–¢–û–ß–ù–ò–ö–ò ===
SOURCES = [
    {"name": "GOODJUDGMENT", "rss": "https://goodjudgment.com/feed/"},
    {"name": "JOHNSHOPKINS", "rss": "https://www.centerforhealthsecurity.org/feed.xml"},
    {"name": "METACULUS", "rss": "https://www.metaculus.com/feed/"},
    {"name": "DNI", "rss": "https://www.dni.gov/index.php/gt2040/feed"},
    {"name": "RANDCORP", "rss": "https://www.rand.org/rss/news.html"},
    {"name": "WEF", "rss": "https://www.weforum.org/feed"},
    {"name": "CSIS", "rss": "https://www.csis.org/rss/all.xml"},
    {"name": "ATLANTICCOUNCIL", "rss": "https://www.atlanticcouncil.org/feed/"},
    {"name": "CHATHAMHOUSE", "rss": "https://www.chathamhouse.org/feed"},
    {"name": "ECONOMIST", "rss": "https://www.economist.com/the-world-this-week/rss.xml"},
    {"name": "BLOOMBERG", "rss": "https://feeds.bloomberg.com/politics/news.rss"},
    {"name": "REUTERS", "rss": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "FOREIGNAFFAIRS", "rss": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "CFR", "rss": "https://www.cfr.org/rss.xml"},
    {"name": "BBC", "rss": "https://feeds.bbci.co.uk/news/world/rss.xml"},
    {"name": "FUTURETIMELINE", "rss": "https://www.futuretimeline.net/blog/feed/feed.xml"},
    {"name": "CARNEGIE", "rss": "https://carnegieendowment.org/feed/rss.xml"},
    {"name": "BRUEGEL", "rss": "https://www.bruegel.org/blog/feed"},
    {"name": "E3G", "rss": "https://www.e3g.org/feed/"}
]

# === –§–ò–õ–¨–¢–†–´ ===
FILTERS = {
    "SVO": [
        r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b", 
        r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b", 
        r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b", 
        r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b", 
        r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b", 
        r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b", 
        r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b", 
        r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b", 
        r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b", 
        r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b", 
        r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b", 
        r"\b—Å–∞–Ω–∫—Ü–∏–∏\b", r"\bsanctions\b", r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b", 
        r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", r"\bsupplies\b", r"\bhimars\b", r"\batacms\b"
    ],
    "crypto": [
        r"\bbitcoin\b", r"\bbtc\b", r"\b–±–∏—Ç–∫–æ–∏–Ω\b", r"\bÊØîÁâπÂ∏Å\b", 
        r"\bethereum\b", r"\beth\b", r"\b—ç—Ñ–∏—Ä\b", r"\b‰ª•Â§™Âùä\b", 
        r"\bbinance coin\b", r"\bbnb\b", r"\busdt\b", r"\btether\b", 
        r"\bxrp\b", r"\bripple\b", r"\bcardano\b", r"\bada\b", 
        r"\bsolana\b", r"\bsol\b", r"\bdoge\b", r"\bdogecoin\b", 
        r"\bavalanche\b", r"\bavax\b", r"\bpolkadot\b", r"\bdot\b", 
        r"\bchainlink\b", r"\blink\b", r"\btron\b", r"\btrx\b", 
        r"\bcbdc\b", r"\bcentral bank digital currency\b", r"\b—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å\b", 
        r"\bdigital yuan\b", r"\beuro digital\b", r"\bdefi\b", r"\b–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã\b", 
        r"\bnft\b", r"\bnon-fungible token\b", r"\bsec\b", r"\b—Ü–± —Ä—Ñ\b", 
        r"\b—Ä–µ–≥—É–ª—è—Ü–∏—è\b", r"\bregulation\b", r"\b–∑–∞–ø—Ä–µ—Ç\b", r"\bban\b", 
        r"\b–º–∞–π–Ω–∏–Ω–≥\b", r"\bmining\b", r"\bhalving\b", r"\b—Ö–∞–ª–≤–∏–Ω–≥\b", 
        r"\b–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\b", r"\bvolatility\b", r"\bcrash\b", r"\b–∫—Ä–∞—Ö\b"
    ],
    "pandemic": [
        r"\bpandemic\b", r"\b–ø–∞–Ω–¥–µ–º–∏—è\b", r"\bÁñ´ÊÉÖ\b", r"\bÿ¨ÿßÿ¶ÿ≠ÿ©\b", 
        r"\boutbreak\b", r"\b–≤—Å–ø—ã—à–∫–∞\b", r"\b—ç–ø–∏–¥–µ–º–∏—è\b", r"\bepidemic\b", 
        r"\bvirus\b", r"\b–≤–∏—Ä—É—Å\b", r"\b–≤–∏—Ä—É—Å—ã\b", r"\bÂèòÂºÇÊ†™\b", 
        r"\bvaccine\b", r"\b–≤–∞–∫—Ü–∏–Ω–∞\b", r"\bÁñ´Ëãó\b", r"\bŸÑŸÇÿßÿ≠\b", 
        r"\bbooster\b", r"\b–±—É—Å—Ç–µ—Ä\b", r"\b—Ä–µ–≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è\b", 
        r"\bquarantine\b", r"\b–∫–∞—Ä–∞–Ω—Ç–∏–Ω\b", r"\bÈöîÁ¶ª\b", r"\bÿ≠ÿ¨ÿ± ÿµÿ≠Ÿä\b", 
        r"\blockdown\b", r"\b–ª–æ–∫–¥–∞—É–Ω\b", r"\bÂ∞ÅÈîÅ\b", 
        r"\bmutation\b", r"\b–º—É—Ç–∞—Ü–∏—è\b", r"\bÂèòÂºÇ\b", 
        r"\bstrain\b", r"\b—à—Ç–∞–º–º\b", r"\bomicron\b", r"\bdelta\b", 
        r"\bbiosafety\b", r"\b–±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\b", r"\bÁîüÁâ©ÂÆâÂÖ®\b", 
        r"\blab leak\b", r"\b–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —É—Ç–µ—á–∫–∞\b", r"\bÂÆûÈ™åÂÆ§Ê≥ÑÊºè\b", 
        r"\bgain of function\b", r"\b—É—Å–∏–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\b", 
        r"\bwho\b", r"\b–≤–æ–∑\b", r"\bcdc\b", r"\b—Ä–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä\b", 
        r"\binfection rate\b", r"\b–∑–∞—Ä–∞–∑–Ω–æ—Å—Ç—å\b", r"\bÊ≠ª‰∫°Áéá\b", 
        r"\bhospitalization\b", r"\b–≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è\b"
    ]
}

# === –§–£–ù–ö–¶–ò–ò –ü–ï–†–ï–í–û–î–ê ===
async def translate_to_russian(text: str) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫"""
    if not text or len(text) < 5:
        return text
    
    # –ï—Å–ª–∏ —É–∂–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if re.search(r'[–∞-—è—ë]', text[:100]):
        return text
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://libretranslate.de/translate",
                json={
                    "q": text[:500],
                    "source": "auto",
                    "target": "ru"
                },
                timeout=15
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data.get("translatedText", text)
    except Exception as e:
        logger.warning(f"‚ùå –û—à–∏–±–∫–∞ LibreTranslate: {str(e)}")
    
    return text

# === –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ù–û–°–¢–ò –ò–°–¢–û–ß–ù–ò–ö–û–í ===
async def check_sources():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç"""
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
    available = []
    
    async with aiohttp.ClientSession(headers={
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }) as session:
        for source in SOURCES:
            try:
                async with session.get(source["rss"], timeout=10) as response:
                    if response.status == 200:
                        available.append(source["name"])
            except:
                pass
    
    logger.info(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ({len(available)}): {', '.join(available)}")
    return available

# === –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò ===
async def get_articles(available_sources):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    articles = []
    
    for source in SOURCES:
        if source["name"] not in available_sources:
            continue
            
        try:
            async with aiohttp.ClientSession(headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }) as session:
                async with session.get(source["rss"], timeout=15) as response:
                    if response.status != 200:
                        continue
                    
                    content = await response.text()
                    feed = feedparser.parse(content)
                    
                    for entry in feed.entries[:3]:
                        lead = ""
                        if hasattr(entry, 'summary'):
                            lead = entry.summary[:300] + "..." if entry.summary else ""
                        
                        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ª–∏–¥
                        translated_title = await translate_to_russian(entry.title)
                        translated_lead = await translate_to_russian(lead) if lead else ""
                        
                        articles.append({
                            "title": translated_title,
                            "url": entry.link,
                            "source": source["name"],
                            "lead": translated_lead,
                            "original_title": entry.title,
                            "original_lead": lead
                        })
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {source['name']}: {str(e)}")
    
    return articles

def detect_category(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º"""
    text_lower = text.lower()
    
    for category, patterns in FILTERS.items():
        for pattern in patterns:
            if re.search(pattern, text_lower, re.IGNORECASE | re.UNICODE):
                return category
    return None

async def send_to_telegram(article: dict, category: str):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram –∫–∞–Ω–∞–ª—ã"""
    message = (
        f"<b>{article['source']}</b>: {article['title']}\n\n"
        f"{article['lead']}\n\n"
        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {article['url']}"
    )
    
    for channel_id in CHANNEL_IDS:
        if not channel_id:
            continue
            
        try:
            await BOT.send_message(
                chat_id=channel_id,
                text=message,
                parse_mode="HTML",
                disable_web_page_preview=True
            )
            logger.info(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {channel_id}: {article['title'][:30]}...")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ {channel_id}: {str(e)}")

# === HTTP-—Å–µ—Ä–≤–µ—Ä –¥–ª—è Render (health check) ===
class HealthCheckHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path in ["/", "/health"]:
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b"OK")
        else:
            self.send_response(404)
            self.end_headers()

def run_http_server():
    server = HTTPServer(("", PORT), HealthCheckHandler)
    logger.info(f"üåê Health check server –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {PORT}")
    server.serve_forever()

# === –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ===
async def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞"""
    try:
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –ø–æ –†–æ—Å—Å–∏–∏/–£–∫—Ä–∞–∏–Ω–µ")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º HTTP-—Å–µ—Ä–≤–µ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ –¥–ª—è health check
        http_thread = threading.Thread(target=run_http_server, daemon=True)
        http_thread.start()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        available_sources = await check_sources()
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π
        articles = await get_articles(available_sources)
        sent_count = 0
        
        for article in articles:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            exists = SUPABASE.table("news_articles").select("id").eq("url", article["url"]).execute()
            if exists.data:
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            full_text = f"{article['title']} {article.get('lead', '')}"
            category = detect_category(full_text)
            
            if not category:
                continue
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            await send_to_telegram(article, category)
            sent_count += 1
            
            SUPABASE.table("news_articles").insert({
                "title": article["title"],
                "source_name": article["source"],
                "url": article["url"],
                "category": category,
                "published_at": datetime.utcnow().isoformat()
            }).execute()
            
            await asyncio.sleep(1.5)
        
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent_count} —Å—Ç–∞—Ç–µ–π")
        
    except Exception as e:
        logger.exception(f"üî• –§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
