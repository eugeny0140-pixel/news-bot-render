import os
import re
import asyncio
import logging
from datetime import datetime
from telegram import Bot
from supabase import create_client
import aiohttp
import feedparser

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHANNELS = [os.getenv("CHANNEL_ID1"), os.getenv("CHANNEL_ID2")]
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

if not all([TELEGRAM_TOKEN, CHANNELS[0], CHANNELS[1], SUPABASE_URL, SUPABASE_KEY]):
    raise ValueError("‚ùå –ù–µ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã")

BOT = Bot(token=TELEGRAM_TOKEN)
SUPABASE = create_client(SUPABASE_URL, SUPABASE_KEY)

SOURCES = [
    {"name": "GOODJUDGMENT", "url": "https://www.goodjudgment.com/feed"},
    {"name": "JOHNSHOPKINS", "url": "https://www.centerforhealthsecurity.org/feed.xml"},
    {"name": "METACULUS", "url": "https://www.metaculus.com/feed/"},
    {"name": "DNI", "url": "https://www.dni.gov/index.php/gt2040-feed"},
    {"name": "RANDCORP", "url": "https://www.rand.org/rss/news.html"},
    {"name": "WEF", "url": "https://www.weforum.org/feed"},
    {"name": "CSIS", "url": "https://www.csis.org/rss/all.xml"},
    {"name": "ATLANTICCOUNCIL", "url": "https://www.atlanticcouncil.org/feed/"},
    {"name": "CHATHAMHOUSE", "url": "https://www.chathamhouse.org/feed"},
    {"name": "ECONOMIST", "url": "https://www.economist.com/the-world-this-week/rss.xml"},
    {"name": "BLOOMBERG", "url": "https://feeds.bloomberg.com/politics/news.rss"},
    {"name": "REUTERS", "url": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "FOREIGNAFFAIRS", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "CFR", "url": "https://www.cfr.org/rss.xml"},
    {"name": "BBCFUTURE", "url": "https://feeds.bbci.co.uk/news/world/rss.xml"},
    {"name": "FUTURETIMELINE", "url": "https://www.futuretimeline.net/blog/feed/"},
    {"name": "CARNEGIE", "url": "https://carnegieendowment.org/rss/all.xml"},
    {"name": "BRUEGEL", "url": "https://www.bruegel.org/blog/feed"},
    {"name": "E3G", "url": "https://www.e3g.org/feed/"}
]

# === –§–ò–õ–¨–¢–†–´ –ü–û –†–û–°–°–ò–ò –ò –£–ö–†–ê–ò–ù–ï ===
FILTERS = {
    "SVO": [
        # –í–æ–µ–Ω–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è
        r"–≤–æ–µ–Ω–Ω–∞—è\s+–æ–ø–µ—Ä–∞—Ü–∏[–∏—è]\s+–Ω–∞\s+—É–∫—Ä–∞–∏–Ω–µ", r"—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏[–∏—è]\s+–Ω–∞\s+—É–∫—Ä–∞–∏–Ω–µ", 
        r"—Ä–æ—Å—Å–∏–π—Å–∫–∞—è\s+–∞—Ä–º–∏—è\s+–≤\s+—É–∫—Ä–∞–∏–Ω–µ", r"–≤—Å\s+—Ä—Ñ\s+–Ω–∞\s+–¥–æ–Ω–±–∞—Å—Å–µ", r"–¥–Ω—Ä\s+–ª–Ω—Ä\s+–ø—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ",
        
        # –£–∫—Ä–∞–∏–Ω—Å–∫–∏–µ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏
        r"(–¥–æ–Ω–±–∞—Å—Å|–¥–æ–Ω–µ—Ü–∫|–ª—É–≥–∞–Ω—Å–∫|—Ö–µ—Ä—Å–æ–Ω|–∑–∞–ø–æ—Ä–æ–∂—å–µ|–º–∞—Ä–∏—É–ø–æ–ª—å)\s+(–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏[–µ—è]|–∫–æ–Ω—Ç—Ä–æ–ª—å\s+—Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö\s+–≤–æ–π—Å–∫)",
        
        # –í–æ–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        r"(—É–¥–∞—Ä|–∞—Ç–∞–∫–∞|–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ)\s+(—Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö|–≤—Å\s+—Ä—Ñ)\s+(–≤–æ–π—Å–∫|—Å–∏–ª)\s+(–Ω–∞|–≤)\s+(–∫–∏–µ–≤|—Ö–∞—Ä—å–∫–æ–≤|–æ–¥–µ—Å—Å–∞)",
        r"—Å–±–∏—Ç[–æ—ã–∏]\s+(—Ä–æ—Å—Å–∏–π—Å–∫|—É–∫—Ä–∞–∏–Ω—Å–∫)\s+(—Å–∞–º–æ–ª–µ—Ç|–¥—Ä–æ–Ω|—Ä–∞–∫–µ—Ç)",
        
        # –°–∞–Ω–∫—Ü–∏–∏
        r"—Å–∞–Ω–∫—Ü–∏–∏\s+(–ø—Ä–æ—Ç–∏–≤|–≤\s+–æ—Ç–Ω–æ—à–µ–Ω–∏–∏)\s+(—Ä–æ—Å—Å–∏[–∏—è]|—Ä—Ñ|—Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö\s+–∫–æ–º–ø–∞–Ω–∏–π)",
        r"(–∑–∞–ø—Ä–µ—Ç|–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ)\s+–Ω–∞\s+(–Ω–µ—Ñ—Ç—å|–≥–∞–∑)\s+–∏–∑\s+—Ä–æ—Å—Å–∏[–∏]",
        r"—Å–µ–≤–µ—Ä–Ω—ã–π\s+–ø–æ—Ç–æ–∫\s+(–ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω|—Ä–∞–∑—Ä—É—à–µ–Ω)"
    ],
    "crypto": [
        # –¶–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å
        r"—Ü–∏—Ñ—Ä–æ–≤–æ–π\s+—Ä—É–±–ª—å", r"digital\s+ruble", r"—Ü–∏—Ñ—Ä–æ–≤–∞—è\s+–≤–∞–ª—é—Ç[–∞—ã]\s+—Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ\s+–±–∞–Ω–∫–∞",
        
        # –°–∞–Ω–∫—Ü–∏–∏ –∏ –∫—Ä–∏–ø—Ç–∞
        r"(—Å–∞–Ω–∫—Ü–∏–∏\s+–ø—Ä–æ—Ç–∏–≤\s+—Ä—Ñ|—Ä–æ—Å—Å–∏–π—Å–∫–∏–µ\s+—Ö–∞–∫–µ—Ä—ã)\s+(–±–∏—Ç–∫–æ–∏–Ω|bitcoin|–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç[–∞—ã])",
        r"—Ä–æ—Å—Å–∏—è\s+(–∏—Å–ø–æ–ª—å–∑—É–µ—Ç|–æ—Ç–º—ã–≤–∞–µ—Ç)\s+–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç[—É—ã]",
        
        # –†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –†–§
        r"(—Ü–±\s+—Ä—Ñ|–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ\s+—Ä—Ñ)\s+(—Ä–∞–∑—Ä–µ—à–∞–µ—Ç|–∑–∞–ø—Ä–µ—â–∞–µ—Ç|—Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç)\s+–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç[—ã—É]",
        r"–º–∞–π–Ω–∏–Ω–≥\s+–≤\s+—Ä–æ—Å—Å–∏–∏\s+(–ª–µ–≥–∞–ª–∏–∑–æ–≤–∞–Ω|–∑–∞–ø—Ä–µ—â–µ–Ω)",
        
        # –ö—Ä–∏–ø—Ç–æ–±–∏—Ä–∂–∏ –∏ –†–§
        r"(binance|bybit)\s+(–±–ª–æ–∫–∏—Ä—É–µ—Ç|–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç)\s+—Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö\s+–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
    ]
}

# === –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò ===
async def translate_to_russian(text: str) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫"""
    if not text or len(text) < 5:
        return text
    
    # –ï—Å–ª–∏ —É–∂–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if re.search(r'[–∞-—è—ë]', text[:100]):
        return text
    
    # –ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —á–µ—Ä–µ–∑ LibreTranslate
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://libretranslate.de/translate",
                json={"q": text[:500], "source": "auto", "target": "ru"},
                timeout=15
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data.get("translatedText", text)
    except Exception as e:
        logger.warning(f"LibreTranslate –æ—à–∏–±–∫–∞: {str(e)}")
    
    return text

async def get_articles():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç–∞—Ç–µ–π –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    articles = []
    
    for source in SOURCES:
        try:
            async with aiohttp.ClientSession(headers={'User-Agent': 'Mozilla/5.0'}) as session:
                async with session.get(source["url"], timeout=10) as response:
                    if response.status != 200:
                        continue
                    
                    feed = feedparser.parse(await response.text())
                    for entry in feed.entries[:3]:
                        lead = entry.summary[:300] + "..." if hasattr(entry, 'summary') else ""
                        
                        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ª–∏–¥
                        translated_title = await translate_to_russian(entry.title)
                        translated_lead = await translate_to_russian(lead)
                        
                        articles.append({
                            "title": translated_title,
                            "url": entry.link,
                            "source": source["name"],
                            "lead": translated_lead
                        })
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {source['name']}: {str(e)}")
    
    logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π")
    return articles

def detect_category(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —Ç–æ—á–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º"""
    text_lower = text.lower()
    
    for category, patterns in FILTERS.items():
        if any(re.search(p, text_lower, re.IGNORECASE | re.UNICODE) for p in patterns):
            return category
    return None

async def send_to_telegram(article: dict, category: str):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ë–ï–ó –•–ï–®–¢–ï–ì–ê"""
    message = (
        f"<b>{article['source']}</b>: {article['title']}\n\n"
        f"{article['lead']}\n\n"
        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {article['url']}"
    )
    
    for channel in CHANNELS:
        try:
            await BOT.send_message(
                chat_id=channel,
                text=message,
                parse_mode="HTML",
                disable_web_page_preview=True
            )
            logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {channel}: {article['title'][:25]}...")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ {channel}: {str(e)}")

async def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞"""
    try:
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –ø–æ –†–æ—Å—Å–∏–∏/–£–∫—Ä–∞–∏–Ω–µ")
        articles = await get_articles()
        
        for article in articles:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –±–∞–∑–µ - –ò–°–ü–†–ê–í–õ–ï–ù–û
            exists = SUPABASE.table("news_articles").select("id").eq("url", article["url"]).execute()
            if exists.data:  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –¥–æ–±–∞–≤–ª–µ–Ω–æ .data
                logger.info(f"‚ôªÔ∏è –î—É–±–ª–∏–∫–∞—Ç: {article['url']}")
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category = detect_category(f"{article['title']} {article['lead']}")
            if not category:
                continue
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
            await send_to_telegram(article, category)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É
            SUPABASE.table("news_articles").insert({
                "title": article["title"],
                "source_name": article["source"],
                "url": article["url"],
                "category": category,
                "published_at": datetime.utcnow().isoformat()
            }).execute()
            
            await asyncio.sleep(1.5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–∞–º–∏
        
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {len(articles)} —Å—Ç–∞—Ç–µ–π")
        
    except Exception as e:
        logger.exception(f"üî• –§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
