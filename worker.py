import os
import re
import asyncio
import logging
from datetime import datetime, UTC
from telegram import Bot
from supabase import create_client
import aiohttp
import feedparser
from http.server import BaseHTTPRequestHandler, HTTPServer
import threading
import html

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHANNEL_IDS = [os.getenv("CHANNEL_ID1"), os.getenv("CHANNEL_ID2")]
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
PORT = int(os.getenv("PORT", 10000))

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
required_vars = ["TELEGRAM_TOKEN", "CHANNEL_ID1", "SUPABASE_URL", "SUPABASE_KEY"]
missing_vars = [var for var in required_vars if not os.getenv(var)]
if missing_vars:
    logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {', '.join(missing_vars)}")
    exit(1)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
BOT = Bot(token=TELEGRAM_TOKEN)
SUPABASE = create_client(SUPABASE_URL, SUPABASE_KEY)

# === –†–ê–ë–û–ß–ò–ï –ò–°–¢–û–ß–ù–ò–ö–ò (–ø—Ä–æ–≤–µ—Ä–µ–Ω—ã 11.11.2025) ===
SOURCES = [
    {"name": "GOODJUDGMENT", "rss": "https://goodjudgment.com/feed/"},
    {"name": "JOHNSHOPKINS", "rss": "https://www.centerforhealthsecurity.org/feed.xml"},
    {"name": "METACULUS", "rss": "https://www.metaculus.com/feed/"},
    {"name": "DNI", "rss": "https://www.dni.gov/index.php/gt2040/feed"},
    {"name": "RAND", "rss": "https://www.rand.org/rss/news.html"},
    {"name": "WEF", "rss": "https://www.weforum.org/feed"},
    {"name": "CSIS", "rss": "https://www.csis.org/rss/all.xml"},
    {"name": "ATLANTICCOUNCIL", "rss": "https://www.atlanticcouncil.org/feed/"},
    {"name": "CHATHAMHOUSE", "rss": "https://www.chathamhouse.org/feed"},
    {"name": "ECONOMIST", "rss": "https://www.economist.com/the-world-this-week/rss.xml"},
    {"name": "BLOOMBERG", "rss": "https://feeds.bloomberg.com/politics/news.rss"},
    {"name": "REUTERS", "rss": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "FOREIGNAFFAIRS", "rss": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "CFR", "rss": "https://www.cfr.org/rss.xml"},
    {"name": "BBC", "rss": "https://feeds.bbci.co.uk/news/world/rss.xml"},
    {"name": "FUTURETIMELINE", "rss": "https://www.futuretimeline.net/blog/feed/feed.xml"},
    {"name": "CARNEGIE", "rss": "https://carnegieendowment.org/news/rss.xml"},
    {"name": "BRUEGEL", "rss": "https://www.bruegel.org/blog/feed"},
    {"name": "E3G", "rss": "https://www.e3g.org/feed/"}
]

# === –§–ò–õ–¨–¢–†–´ –ü–û –†–û–°–°–ò–ò –ò –£–ö–†–ê–ò–ù–ï ===
FILTERS = {
    "SVO": [
        r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
        r"\bukraine\b", r"\bukrainian\b", r"\bzelensky\b", r"\bkyiv\b", r"\bkiev\b",
        r"\bcrimea\b", r"\bdonbas\b", r"\bsanction[s]?\b", r"\bgazprom\b",
        r"\bnord\s?stream\b", r"\bwagner\b", r"\blavrov\b", r"\bshoigu\b",
        r"\bmedvedev\b", r"\bpeskov\b", r"\bnato\b", r"\beuropa\b", r"\busa\b",
        r"\bsoviet\b", r"\bussr\b", r"\bpost\W?soviet\b",
        r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b", 
        r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b", 
        r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b", 
        r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b", 
        r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b", 
        r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b", 
        r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b", 
        r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b", 
        r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b", 
        r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b", 
        r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b", 
        r"\b—Å–∞–Ω–∫—Ü–∏–∏\b", r"\bsanctions\b", r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b", 
        r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", r"\bsupplies\b", r"\bhimars\b", r"\batacms\b"
    ],
    "crypto": [
        r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
        r"\b—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å\b", r"\bsanction[s]?\b", r"\bcbr\b", r"\b—Ä–æ—Å—Å–∏–∏\b",
        r"\bbitcoin\b", r"\bbtc\b", r"\b–±–∏—Ç–∫–æ–∏–Ω\b", r"\bÊØîÁâπÂ∏Å\b", 
        r"\bethereum\b", r"\beth\b", r"\b—ç—Ñ–∏—Ä\b", r"\b‰ª•Â§™Âùä\b", 
        r"\bbinance\b", r"\bbnb\b", r"\busdt\b", r"\btether\b", 
        r"\bxrp\b", r"\bripple\b", r"\bcardano\b", r"\bada\b", 
        r"\bsolana\b", r"\bsol\b", r"\bdoge\b", r"\bdogecoin\b", 
        r"\bavalanche\b", r"\bavax\b", r"\bpolkadot\b", r"\bdot\b", 
        r"\bchainlink\b", r"\blink\b", r"\btron\b", r"\btrx\b", 
        r"\bcbdc\b", r"\bcentral bank digital currency\b", r"\b—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å\b", 
        r"\bdigital yuan\b", r"\beuro digital\b", r"\bdefi\b", r"\b–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã\b", 
        r"\bnft\b", r"\bnon-fungible token\b", r"\bsec\b", r"\b—Ü–± —Ä—Ñ\b", 
        r"\b—Ä–µ–≥—É–ª—è—Ü–∏—è\b", r"\bregulation\b", r"\b–∑–∞–ø—Ä–µ—Ç\b", r"\bban\b", 
        r"\b–º–∞–π–Ω–∏–Ω–≥\b", r"\bmining\b", r"\bhalving\b", r"\b—Ö–∞–ª–≤–∏–Ω–≥\b", 
        r"\b–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\b", r"\bvolatility\b", r"\bcrash\b", r"\b–∫—Ä–∞—Ö\b"
    ]
}

# === –§–£–ù–ö–¶–ò–ò –û–ß–ò–°–¢–ö–ò –ò –ü–ï–†–ï–í–û–î–ê ===
def clean_html(raw: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç HTML-—Ç–µ–≥–∏ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã."""
    if not raw:
        return ""
    # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
    text = re.sub(r'<[^>]+>', '', raw)
    # –ó–∞–º–µ–Ω—è–µ–º HTML —Å—É—â–Ω–æ—Å—Ç–∏
    text = html.unescape(text)
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    text = re.sub(r'\s+', ' ', text).strip()
    return text[:1000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

async def translate_to_russian(text: str) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫"""
    if not text or len(text) < 5:
        return text
    
    # –ï—Å–ª–∏ —É–∂–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if re.search(r'[–∞-—è—ë]', text[:100]):
        return text
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://libretranslate.de/translate",  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π URL
                json={
                    "q": text[:500],
                    "source": "auto",
                    "target": "ru"
                },
                timeout=15
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data.get("translatedText", text)
    except Exception as e:
        logger.warning(f"‚ùå –û—à–∏–±–∫–∞ LibreTranslate: {str(e)}")
    
    return text

# === –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ù–û–°–¢–ò –ò–°–¢–û–ß–ù–ò–ö–û–í ===
async def check_sources():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç"""
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
    available = []
    
    async with aiohttp.ClientSession(headers={
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }) as session:
        tasks = []
        for source in SOURCES:
            tasks.append(session.get(source["rss"], timeout=10))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for i, result in enumerate(results):
            source_name = SOURCES[i]["name"]
            if isinstance(result, Exception):
                logger.warning(f"‚ö†Ô∏è {source_name}: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({str(result)})")
            elif result.status == 200:
                available.append(source_name)
                logger.info(f"‚úÖ {source_name}: –¥–æ—Å—Ç—É–ø–µ–Ω")
            else:
                logger.warning(f"‚ö†Ô∏è {source_name}: —Å—Ç–∞—Ç—É—Å {result.status}")
    
    logger.info(f"üìä –†–∞–±–æ—á–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(available)} –∏–∑ {len(SOURCES)}")
    return available

# === –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò ===
async def get_articles(available_sources):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    articles = []
    
    for source in SOURCES:
        if source["name"] not in available_sources:
            continue
            
        try:
            async with aiohttp.ClientSession(headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }) as session:
                async with session.get(source["rss"], timeout=15) as response:
                    if response.status != 200:
                        continue
                    
                    content = await response.text()
                    feed = feedparser.parse(content)
                    
                    logger.info(f"üì∞ {source['name']}: –ø–æ–ª—É—á–µ–Ω–æ {len(feed.entries)} –∑–∞–ø–∏—Å–µ–π")
                    
                    for entry in feed.entries[:2]:  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 2 —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ
                        title = clean_html(entry.get("title", ""))
                        url = entry.get("link", "").strip()
                        lead = ""
                        
                        # –ü–æ–ª—É—á–∞–µ–º –ª–∏–¥ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–ª–µ–π
                        for field in ["summary", "description", "content"]:
                            if hasattr(entry, field):
                                content_value = entry.get(field, "")
                                if isinstance(content_value, list):
                                    content_value = content_value[0].get("value", "") if content_value else ""
                                if content_value:
                                    lead = clean_html(content_value)
                                    break
                        
                        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ª–∏–¥ 300 —Å–∏–º–≤–æ–ª–∞–º–∏
                        lead = lead[:300] + "..." if len(lead) > 300 else lead
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç–∞—Ç—å–∏
                        if not title or not url or not lead:
                            continue
                        
                        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ª–∏–¥
                        translated_title = await translate_to_russian(title)
                        translated_lead = await translate_to_russian(lead)
                        
                        articles.append({
                            "title": translated_title,
                            "url": url,
                            "source": source["name"],
                            "lead": translated_lead
                        })
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {source['name']}: {str(e)}")
    
    logger.info(f"‚ú® –ü–æ–ª—É—á–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(articles)}")
    return articles

def detect_category(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¢–û–õ–¨–ö–û –ø—Ä–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–∏ –†–æ—Å—Å–∏–∏/–£–∫—Ä–∞–∏–Ω—ã"""
    text_lower = text.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –¥–≤–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    for category, patterns in FILTERS.items():
        if any(re.search(pattern, text_lower, re.IGNORECASE | re.UNICODE) for pattern in patterns):
            return category
    return None

async def send_to_telegram(article: dict, category: str):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram –∫–∞–Ω–∞–ª—ã"""
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    message = (
        f"<b>{article['source']}</b>: {html.escape(article['title'])}\n\n"
        f"{html.escape(article['lead'])}\n\n"
        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {article['url']}"
    )
    
    for channel_id in CHANNEL_IDS:
        if not channel_id:
            continue
            
        try:
            await BOT.send_message(
                chat_id=channel_id,
                text=message,
                parse_mode="HTML",
                disable_web_page_preview=True
            )
            logger.info(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {channel_id}: {article['title'][:30]}...")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ {channel_id}: {str(e)}")

# === HTTP-—Å–µ—Ä–≤–µ—Ä –¥–ª—è Render (health check) ===
class HealthCheckHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path in ["/", "/health"]:
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b"OK")
        else:
            self.send_response(404)
            self.end_headers()

def run_http_server():
    server = HTTPServer(("", PORT), HealthCheckHandler)
    logger.info(f"üåê Health check server –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {PORT}")
    server.serve_forever()

# === –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ===
async def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞"""
    try:
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –ø–æ –†–æ—Å—Å–∏–∏/–£–∫—Ä–∞–∏–Ω–µ")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º HTTP-—Å–µ—Ä–≤–µ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ –¥–ª—è health check
        http_thread = threading.Thread(target=run_http_server, daemon=True)
        http_thread.start()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        available_sources = await check_sources()
        if not available_sources:
            logger.error("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤! –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            return
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π
        articles = await get_articles(available_sources)
        sent_count = 0
        
        for article in articles:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            exists = SUPABASE.table("news_articles").select("id").eq("url", article["url"]).execute()
            if exists.
                logger.info(f"‚ôªÔ∏è –î—É–±–ª–∏–∫–∞—Ç: {article['url']}")
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Ç–æ–ª—å–∫–æ SVO –∏ crypto)
            full_text = f"{article['title']} {article.get('lead', '')}"
            category = detect_category(full_text)
            
            if not category:
                logger.debug(f"‚ùå –ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞–º: {article['title'][:50]}...")
                continue
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            await send_to_telegram(article, category)
            sent_count += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π
            SUPABASE.table("news_articles").insert({
                "title": article["title"],
                "source_name": article["source"],
                "url": article["url"],
                "category": category,
                "published_at": datetime.now(UTC).isoformat()  # –ò–°–ü–†–ê–í–õ–ï–ù–û: —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –º–µ—Ç–æ–¥
            }).execute()
            
            await asyncio.sleep(1.5)
        
        logger.info(f"üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent_count} —Å—Ç–∞—Ç–µ–π –∏–∑ {len(articles)}")
        
    except Exception as e:
        logger.exception(f"üî• –§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
