import os
import re
import asyncio
import logging
from datetime import datetime
from telegram import Bot
from supabase import create_client
import aiohttp
import feedparser

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHANNELS = [os.getenv("CHANNEL_ID1"), os.getenv("CHANNEL_ID2")]
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

if not all([TELEGRAM_TOKEN, CHANNELS[0], CHANNELS[1], SUPABASE_URL, SUPABASE_KEY]):
    raise ValueError("‚ùå –ù–µ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã")

BOT = Bot(token=TELEGRAM_TOKEN)
SUPABASE = create_client(SUPABASE_URL, SUPABASE_KEY)

# === –ü–†–û–í–ï–†–ï–ù–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò (–≤—Å–µ —Ä–∞–±–æ—Ç–∞—é—Ç 11.11.2025) ===
SOURCES = [
    {"name": "GOODJUDGMENT", "url": "https://goodjudgment.com/feed/"},
    {"name": "JOHNSHOPKINS", "url": "https://www.centerforhealthsecurity.org/feed.xml"},
    {"name": "METACULUS", "url": "https://www.metaculus.com/feed/"},
    {"name": "DNI", "url": "https://www.dni.gov/index.php/gt2040/feed"},
    {"name": "RANDCORP", "url": "https://www.rand.org/rss/news.html"},
    {"name": "WEF", "url": "https://www.weforum.org/feed"},
    {"name": "CSIS", "url": "https://www.csis.org/rss/all.xml"},
    {"name": "ATLANTICCOUNCIL", "url": "https://www.atlanticcouncil.org/feed/"},
    {"name": "CHATHAMHOUSE", "url": "https://www.chathamhouse.org/feed"},
    {"name": "ECONOMIST", "url": "https://www.economist.com/the-world-this-week/rss.xml"},
    {"name": "BLOOMBERG", "url": "https://feeds.bloomberg.com/politics/news.rss"},
    {"name": "REUTERS", "url": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "FOREIGNAFFAIRS", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "CFR", "url": "https://www.cfr.org/rss.xml"},
    {"name": "BBCFUTURE", "url": "https://feeds.bbci.co.uk/news/world/rss.xml"},
    {"name": "FUTURETIMELINE", "url": "https://www.futuretimeline.net/blog/feed/feed.xml"},
    {"name": "CARNEGIE", "url": "https://carnegieendowment.org/rss/all.xml"},
    {"name": "BRUEGEL", "url": "https://www.bruegel.org/feed"},
    {"name": "E3G", "url": "https://www.e3g.org/feed/"}
]

# === –û–ë–ù–û–í–õ–ï–ù–ù–´–ï –§–ò–õ–¨–¢–†–´ ===
FILTERS = {
    "SVO": [
        r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b", 
        r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b", 
        r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b", 
        r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b", 
        r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b", 
        r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b", 
        r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b", 
        r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b", 
        r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b", 
        r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b", 
        r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b", 
        r"\b—Å–∞–Ω–∫—Ü–∏–∏\b", r"\bsanctions\b", r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b", 
        r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", r"\bsupplies\b", r"\bhimars\b", r"\batacms\b"
    ],
    "crypto": [
        r"\bbitcoin\b", r"\bbtc\b", r"\b–±–∏—Ç–∫–æ–∏–Ω\b", r"\bÊØîÁâπÂ∏Å\b", 
        r"\bethereum\b", r"\beth\b", r"\b—ç—Ñ–∏—Ä\b", r"\b‰ª•Â§™Âùä\b", 
        r"\bbinance coin\b", r"\bbnb\b", r"\busdt\b", r"\btether\b", 
        r"\bxrp\b", r"\bripple\b", r"\bcardano\b", r"\bada\b", 
        r"\bsolana\b", r"\bsol\b", r"\bdoge\b", r"\bdogecoin\b", 
        r"\bavalanche\b", r"\bavax\b", r"\bpolkadot\b", r"\bdot\b", 
        r"\bchainlink\b", r"\blink\b", r"\btron\b", r"\btrx\b", 
        r"\bcbdc\b", r"\bcentral bank digital currency\b", r"\b—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å\b", 
        r"\bdigital yuan\b", r"\beuro digital\b", r"\bdefi\b", r"\b–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã\b", 
        r"\bnft\b", r"\bnon-fungible token\b", r"\bsec\b", r"\b—Ü–± —Ä—Ñ\b", 
        r"\b—Ä–µ–≥—É–ª—è—Ü–∏—è\b", r"\bregulation\b", r"\b–∑–∞–ø—Ä–µ—Ç\b", r"\bban\b", 
        r"\b–º–∞–π–Ω–∏–Ω–≥\b", r"\bmining\b", r"\bhalving\b", r"\b—Ö–∞–ª–≤–∏–Ω–≥\b", 
        r"\b–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\b", r"\bvolatility\b", r"\bcrash\b", r"\b–∫—Ä–∞—Ö\b"
    ],
    "pandemic": [
        r"\bpandemic\b", r"\b–ø–∞–Ω–¥–µ–º–∏—è\b", r"\bÁñ´ÊÉÖ\b", r"\bÿ¨ÿßÿ¶ÿ≠ÿ©\b", 
        r"\boutbreak\b", r"\b–≤—Å–ø—ã—à–∫–∞\b", r"\b—ç–ø–∏–¥–µ–º–∏—è\b", r"\bepidemic\b", 
        r"\bvirus\b", r"\b–≤–∏—Ä—É—Å\b", r"\b–≤–∏—Ä—É—Å—ã\b", r"\bÂèòÂºÇÊ†™\b", 
        r"\bvaccine\b", r"\b–≤–∞–∫—Ü–∏–Ω–∞\b", r"\bÁñ´Ëãó\b", r"\bŸÑŸÇÿßÿ≠\b", 
        r"\bbooster\b", r"\b–±—É—Å—Ç–µ—Ä\b", r"\b—Ä–µ–≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è\b", 
        r"\bquarantine\b", r"\b–∫–∞—Ä–∞–Ω—Ç–∏–Ω\b", r"\bÈöîÁ¶ª\b", r"\bÿ≠ÿ¨ÿ± ÿµÿ≠Ÿä\b", 
        r"\blockdown\b", r"\b–ª–æ–∫–¥–∞—É–Ω\b", r"\bÂ∞ÅÈîÅ\b", 
        r"\bmutation\b", r"\b–º—É—Ç–∞—Ü–∏—è\b", r"\bÂèòÂºÇ\b", 
        r"\bstrain\b", r"\b—à—Ç–∞–º–º\b", r"\bomicron\b", r"\bdelta\b", 
        r"\bbiosafety\b", r"\b–±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\b", r"\bÁîüÁâ©ÂÆâÂÖ®\b", 
        r"\blab leak\b", r"\b–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —É—Ç–µ—á–∫–∞\b", r"\bÂÆûÈ™åÂÆ§Ê≥ÑÊºè\b", 
        r"\bgain of function\b", r"\b—É—Å–∏–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\b", 
        r"\bwho\b", r"\b–≤–æ–∑\b", r"\bcdc\b", r"\b—Ä–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä\b", 
        r"\binfection rate\b", r"\b–∑–∞—Ä–∞–∑–Ω–æ—Å—Ç—å\b", r"\bÊ≠ª‰∫°Áéá\b", 
        r"\bhospitalization\b", r"\b–≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è\b"
    ]
}

# === –§–£–ù–ö–¶–ò–ò –ü–ï–†–ï–í–û–î–ê –° –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ú URL ===
async def translate_to_russian(text: str) -> str:
    """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º URL"""
    if not text or len(text) < 5:
        return text
    
    # –ï—Å–ª–∏ —É–∂–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if re.search(r'[–∞-—è—ë]', text[:100]):
        return text
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π URL –¥–ª—è LibreTranslate
    translate_url = "https://libretranslate.de/translate"
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                translate_url,
                json={
                    "q": text[:500],
                    "source": "auto",
                    "target": "ru"
                },
                timeout=15
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data.get("translatedText", text)
                else:
                    logger.warning(f"‚ö†Ô∏è LibreTranslate –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status}")
    except Exception as e:
        logger.warning(f"‚ùå –û—à–∏–±–∫–∞ LibreTranslate: {str(e)}")
    
    # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç - Google Translate
    try:
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            "sl": "auto",
            "tl": "ru",
            "q": text[:500],
            "client": "gtx"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(
                url,
                params=params,
                timeout=10
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    translated = ""
                    for item in data[0]:
                        if item[0]:
                            translated += item[0]
                    return translated if translated else text
    except Exception as e:
        logger.warning(f"‚ùå –û—à–∏–±–∫–∞ Google Translate: {str(e)}")
    
    return text

# === –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ù–û–°–¢–ò –ò–°–¢–û–ß–ù–ò–ö–û–í ===
async def check_sources_availability():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç"""
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
    unavailable = []
    
    async with aiohttp.ClientSession(headers={'User-Agent': 'Mozilla/5.0'}) as session:
        for source in SOURCES:
            try:
                async with session.get(source["url"], timeout=8) as response:
                    if response.status != 200:
                        unavailable.append(f"{source['name']} ({response.status})")
            except Exception as e:
                unavailable.append(f"{source['name']} (–æ—à–∏–±–∫–∞: {str(e)})")
    
    if unavailable:
        logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(unavailable)}")
    else:
        logger.info("‚úÖ –í—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã")

# === –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò ===
async def get_articles():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    await check_sources_availability()
    articles = []
    
    for source in SOURCES:
        try:
            async with aiohttp.ClientSession(headers={'User-Agent': 'Mozilla/5.0'}) as session:
                async with session.get(source["url"], timeout=10) as response:
                    if response.status != 200:
                        logger.warning(f"‚ö†Ô∏è {source['name']} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Å—Ç–∞—Ç—É—Å {response.status})")
                        continue
                    
                    content = await response.text()
                    feed = feedparser.parse(content)
                    
                    if not feed.entries:
                        logger.warning(f"‚ö†Ô∏è {source['name']}: –ø—É—Å—Ç–∞—è RSS-–ª–µ–Ω—Ç–∞")
                        continue
                    
                    logger.info(f"‚úÖ {source['name']}: –ø–æ–ª—É—á–µ–Ω–æ {min(3, len(feed.entries))} —Å—Ç–∞—Ç–µ–π")
                    
                    for entry in feed.entries[:3]:
                        lead = ""
                        if hasattr(entry, 'summary'):
                            lead = entry.summary[:300] + "..." if entry.summary else ""
                        
                        # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –¥—Ä—É–≥–æ–º —è–∑—ã–∫–µ
                        translated_title = await translate_to_russian(entry.title)
                        translated_lead = await translate_to_russian(lead) if lead else ""
                        
                        articles.append({
                            "title": translated_title,
                            "url": entry.link,
                            "source": source["name"],
                            "lead": translated_lead,
                            "original_lang": "ru" if re.search(r'[–∞-—è—ë]', entry.title[:100]) else "other"
                        })
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {source['name']}: {str(e)}")
    
    logger.info(f"üìä –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ: {len(articles)} —Å—Ç–∞—Ç–µ–π")
    return articles

def detect_category(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º"""
    text_lower = text.lower()
    
    for category, patterns in FILTERS.items():
        for pattern in patterns:
            if re.search(pattern, text_lower, re.IGNORECASE | re.UNICODE):
                return category
    return None

# === –û–¢–ü–†–ê–í–ö–ê –í TELEGRAM ===
async def send_to_telegram(article: dict, category: str):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram –∫–∞–Ω–∞–ª—ã"""
    message = (
        f"<b>{article['source']}</b>: {article['title']}\n\n"
        f"{article['lead']}\n\n"
        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {article['url']}"
    )
    
    for channel in CHANNELS:
        try:
            await BOT.send_message(
                chat_id=channel,
                text=message,
                parse_mode="HTML",
                disable_web_page_preview=True
            )
            logger.info(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {channel}: {article['title'][:30]}...")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ {channel}: {str(e)}")

# === –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ===
async def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞"""
    try:
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏")
        
        articles = await get_articles()
        sent_count = 0
        
        for article in articles:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            exists = SUPABASE.table("news_articles").select("id").eq("url", article["url"]).execute()
            if exists.data:
                logger.info(f"‚ôªÔ∏è –î—É–±–ª–∏–∫–∞—Ç: {article['url']}")
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            full_text = f"{article['title']} {article.get('lead', '')}"
            category = detect_category(full_text)
            
            if not category:
                logger.debug(f"‚ùå –ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞–º: {article['title'][:50]}...")
                continue
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            await send_to_telegram(article, category)
            sent_count += 1
            
            SUPABASE.table("news_articles").insert({
                "title": article["title"],
                "source_name": article["source"],
                "url": article["url"],
                "category": category,
                "published_at": datetime.utcnow().isoformat()
            }).execute()
            
            await asyncio.sleep(1.5)
        
        logger.info(f"üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent_count} —Å—Ç–∞—Ç–µ–π –∏–∑ {len(articles)}")
        
    except Exception as e:
        logger.exception(f"üî• –§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
